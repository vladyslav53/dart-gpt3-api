import 'dart:async';
import 'dart:convert';
import 'dart:core';
import 'dart:io';

import 'package:http/http.dart' as http;
import 'package:http/http.dart';
import 'package:json_annotation/json_annotation.dart';

part 'openai_gpt3_api.g.dart';

/// Returned by the GPT-3 API when there is an error.
@JsonSerializable()
class InvalidRequestException implements Exception {
  final String message;

  InvalidRequestException(this.message);

  @override
  String toString() {
    return 'InvalidRequestException: $message';
  }

  factory InvalidRequestException.fromJson(Map<String, dynamic> json) =>
      _$InvalidRequestExceptionFromJson(json);
  Map<String, dynamic> toJson() => _$InvalidRequestExceptionToJson(this);
}

@JsonSerializable()
class _CompletionApiParameters {
  _CompletionApiParameters(this.prompt,
      {this.maxTokens = 16,
      this.temperature = 1,
      this.topP = 1,
      this.n = 1,
      this.stream = false,
      this.logprobs,
      this.echo = false,
      this.stop,
      this.presencePenalty = 0,
      this.frequencyPenalty = 0,
      this.bestOf = 1,
      this.logitBias});
  final String prompt;
  final int maxTokens;
  final num temperature;
  final num topP;
  final int n;
  final bool stream;
  final int? logprobs;
  final bool echo;
  final String? stop;
  final num presencePenalty;
  final num frequencyPenalty;
  final int bestOf;
  final Map<String, num>? logitBias;

  Map<String, dynamic> toJson() => _$_CompletionApiParametersToJson(this);
}

/// The API result of a completion task.
@JsonSerializable()
class CompletionApiResult {
  /// The unique id of this result.
  final String id;

  /// What kind of prompt this was, e.g. "text_completion".
  final String object;

  /// A timestamp when the result was generated.
  final int created;

  /// The id of the engine or model used on the OpenAI backend.
  final String model;

  /// The list of n choices generated by GPT-3.
  final List<Choice> choices;

  CompletionApiResult(
      this.id, this.object, this.created, this.model, this.choices);
  factory CompletionApiResult.fromJson(Map<String, dynamic> json) =>
      _$CompletionApiResultFromJson(json);
  Map<String, dynamic> toJson() => _$CompletionApiResultToJson(this);
}

/// A choice in the completion prompt.
@JsonSerializable(includeIfNull: true)
class Choice {
  /// The completion text generated by GPT-3.
  final String text;

  /// The index of the choice in the list.
  final int index;

  /// The logprobs object with further information about the probabilities of tokens.
  /// Only available if the parameter "log_probs" is given in the call.
  final Logprobs? logprobs;

  /// The reason why the text stops, e.g. "length".
  final String finishReason;

  Choice(this.text, this.index, this.finishReason, {this.logprobs});

  factory Choice.fromJson(Map<String, dynamic> json) => _$ChoiceFromJson(json);
  Map<String, dynamic> toJson() => _$ChoiceToJson(this);
}

@JsonSerializable()
class Logprobs {
  /// Offsets of the tokens.
  final List<int> textOffset;

  /// The log probabilities of each token.
  final List<num> tokenLogprobs;

  /// The string representation of each token.
  final List<String> tokens;

  /// The top choices for each token with log probabilities.
  final List<Map<String, num>> topLogprobs;

  Logprobs(this.textOffset, this.tokenLogprobs, this.tokens, this.topLogprobs);

  factory Logprobs.fromJson(Map<String, dynamic> json) =>
      _$LogprobsFromJson(json);
  Map<String, dynamic> toJson() => _$LogprobsToJson(this);
}

@JsonSerializable()
class _SearchApiParameters {
  _SearchApiParameters(this.query,
      {this.documents,
      this.file,
      this.maxRerank = 200,
      this.returnMetadata = false}) {
    if (documents == null && file == null) {
      throw ArgumentError(
          'Either the documents argument or the file argument needs to be provided.');
    }
    if (documents != null && file != null) {
      throw ArgumentError(
          'You can only provide the documents or the file argument, but not both.');
    }
  }
  final String query;
  final String? file;
  final List<String>? documents;
  final int maxRerank;
  final bool returnMetadata;

  Map<String, dynamic> toJson() => _$_SearchApiParametersToJson(this);
}

/// The API result of a search task.
@JsonSerializable()
class SearchApiResult {
  /// The id of the engine or model used on the OpenAI backend.
  final String model;
  final String object;

  /// The data object containing the search results.
  final List<SearchData> data;

  SearchApiResult(this.model, this.object, this.data);

  factory SearchApiResult.fromJson(Map<String, dynamic> json) =>
      _$SearchApiResultFromJson(json);
  Map<String, dynamic> toJson() => _$SearchApiResultToJson(this);
}

@JsonSerializable()
class SearchData {
  /// The index of the document in the list.
  final int document;

  /// What kind of prompt this was, e.g. "search_result".
  final String object;

  /// The semantic search score.
  final num score;

  /// Only available when a file was provided to the API call with return_metadata enabled.
  /// Gives the metadata of the file.
  final String? text;

  SearchData(this.document, this.object, this.score, this.text);

  factory SearchData.fromJson(Map<String, dynamic> json) =>
      _$SearchDataFromJson(json);
  Map<String, dynamic> toJson() => _$SearchDataToJson(this);
}

@JsonSerializable()
class _ClassificationApiParameters {
  _ClassificationApiParameters(this.model, this.query,
      {this.examples,
      this.file,
      this.labels,
      this.searchModel = 'ada',
      this.temperature = 0,
      this.logprobs,
      this.maxExamples = 200,
      this.logitBias,
      this.returnPrompt = false,
      this.returnMetadata = false,
      this.expand}) {
    if (examples == null && file == null) {
      throw ArgumentError(
          'Either the examples argument or the file argument needs to be provided.');
    }
    if (examples != null && file != null) {
      throw ArgumentError(
          'You can only provide the examples or the file argument, but not both.');
    }
  }
  final String model;
  final String query;
  final List<List<String>>? examples;
  final String? file;
  final List<String>? labels;
  final String searchModel;
  final num temperature;
  final int? logprobs;
  final int maxExamples;
  final Map<String, num>? logitBias;
  final bool returnPrompt;
  final bool returnMetadata;
  final List<String>? expand;

  Map<String, dynamic> toJson() => _$_ClassificationApiParametersToJson(this);
}

/// The API result of a classification task.
@JsonSerializable()
class ClassificationApiResult {
  /// The unique id of this result.
  final String completion;

  /// The predicted label for the input query.
  final String label;

  /// The id of the engine or model used on the OpenAI backend.
  final String model;

  /// What kind of prompt this was, e.g. "classification".
  final String object;

  /// The prompt that was given to the API. Only available when "return_prompt" was enabled.
  final String? prompt;

  /// The name of the engine or model used on the OpenAI backend for the search.
  final String searchModel;
  final List<ClassificationExampleData> selectedExamples;

  ClassificationApiResult(this.completion, this.label, this.model, this.object,
      this.prompt, this.searchModel, this.selectedExamples);
  factory ClassificationApiResult.fromJson(Map<String, dynamic> json) =>
      _$ClassificationApiResultFromJson(json);
  Map<String, dynamic> toJson() => _$ClassificationApiResultToJson(this);
}

/// The data for an example given for a classification task.
@JsonSerializable()
class ClassificationExampleData {
  /// The index of the document.
  final int document;

  /// The label of the example text.
  final String label;

  /// The text of the example.
  final String text;

  ClassificationExampleData(this.document, this.label, this.text);
  factory ClassificationExampleData.fromJson(Map<String, dynamic> json) =>
      _$ClassificationExampleDataFromJson(json);
  Map<String, dynamic> toJson() => _$ClassificationExampleDataToJson(this);
}

class GPT3 {
  String apiKey;

  /// Creates the OpenAI GPT-3 helper object.
  ///
  /// You should inject your personal API-key to the program by adding
  /// --dart-define=OPENAI_API_KEY=${OPENAI_API_KEY}
  /// to your flutter arguments.
  GPT3(String apiKey) : apiKey = apiKey;

  Uri _getUri(String apiEndpoint, [Engine engine = Engine.davinci]) {
    var url = Uri.https(
        'api.openai.com', '/v1/engines/${engine.toString()}/$apiEndpoint');
    return url;
  }

  /// Post a HTTP call to the given [url] with the data object [body].
  Future<Response> _postHttpCall(Uri url, Map<String, dynamic> body) {
    return http.post(
      url,
      headers: {
        HttpHeaders.authorizationHeader: 'Bearer $apiKey',
        HttpHeaders.acceptHeader: 'application/json',
        HttpHeaders.contentTypeHeader: 'application/json',
      },
      body: jsonEncode(body),
    );
  }

  /// Catch any exceptions from the GPT-3 backend.
  void _catchExceptions(Map<String, dynamic> data) {
    if (data.containsKey('error')) {
      throw InvalidRequestException.fromJson(data['error']);
    }
  }

  /// Post a 'completion' API request to the OpenAI service.
  ///
  /// Throws an [InvalidRequestException] if something goes wrong on the backend.
  ///
  /// For more information, refer to [the OpenAI documentation](https://beta.openai.com/docs/api-reference/completions/create).
  Future<CompletionApiResult> completion(String prompt,
      {int maxTokens = 16,
      num temperature = 1,
      num topP = 1,
      int n = 1,
      bool stream = false,
      int? logProbs,
      bool echo = false,
      Engine engine = Engine.davinci,
      String? stop,
      num presencePenalty = 0,
      num frequencyPenalty = 0,
      int bestOf = 1,
      Map<String, num>? logitBias}) async {
    var data = _CompletionApiParameters(prompt,
        maxTokens: maxTokens,
        temperature: temperature,
        bestOf: bestOf,
        echo: echo,
        frequencyPenalty: frequencyPenalty,
        logitBias: logitBias,
        logprobs: logProbs,
        n: n,
        presencePenalty: presencePenalty,
        stop: stop,
        stream: stream,
        topP: topP);

    var reqData = data.toJson();
    var response = await _postHttpCall(_getUri('completions', engine), reqData);
    Map<String, dynamic> map = json.decode(response.body);
    _catchExceptions(map);
    return CompletionApiResult.fromJson(map);
  }

  /// Given a query and a set of documents or labels, the model ranks each
  /// document based on its semantic similarity to the provided [query].
  ///
  /// If [documents] and [file] are both null or both not-null, a [ArgumentError] is thrown.
  /// Throws an [InvalidRequestException] if something goes wrong on the backend.
  /// For more information, refer to [the OpenAI documentation](https://beta.openai.com/docs/api-reference/searches)
  Future<SearchApiResult> search(String query,
      {List<String>? documents,
      String? file,
      int maxRerank = 200,
      bool returnMetadata = false,
      Engine engine = Engine.davinci}) async {
    var data = _SearchApiParameters(query,
        documents: documents,
        file: file,
        maxRerank: maxRerank,
        returnMetadata: returnMetadata);
    var reqData = data.toJson();
    var response = await _postHttpCall(_getUri('search', engine), reqData);
    Map<String, dynamic> map = json.decode(response.body);
    _catchExceptions(map);
    return SearchApiResult.fromJson(map);
  }

  /// Classifies the specified query using provided examples.
  ///
  /// The endpoint first searches over the labeled examples to select the
  /// ones most relevant for the particular query. Then, the relevant examples
  /// are combined with the query to construct a prompt to produce the final
  /// label via the completions endpoint.
  ///
  /// Labeled examples can be provided via an uploaded file, or explicitly
  /// listed in the request using the examples parameter for quick tests
  /// and small scale use cases.
  ///
  /// If [examples] and [file] are both null or both not-null, a [ArgumentError] is thrown.
  /// Throws an [InvalidRequestException] if something goes wrong on the backend.
  ///
  /// For more information, refer to [the OpenAI documentation](https://beta.openai.com/docs/api-reference/classifications)
  Future<ClassificationApiResult> classification(Engine model, String query,
      {List<List<String>>? examples,
      String? file,
      List<String>? labels,
      String searchModel = 'ada',
      num temperature = 0,
      int? logprobs,
      int maxExamples = 200,
      Map<String, num>? logitBias,
      bool returnPrompt = false,
      bool returnMetadata = false,
      List<String>? expand}) async {
    var data = _ClassificationApiParameters(model.toString(), query,
        returnMetadata: returnMetadata,
        file: file,
        logitBias: logitBias,
        temperature: temperature,
        examples: examples,
        expand: expand,
        labels: labels,
        logprobs: logprobs,
        maxExamples: maxExamples,
        returnPrompt: returnPrompt,
        searchModel: searchModel);
    var reqData = data.toJson();
    var response = await _postHttpCall(
        Uri.https('api.openai.com', '/v1/classifications'), reqData);
    Map<String, dynamic> map = json.decode(response.body);
    _catchExceptions(map);
    return ClassificationApiResult.fromJson(map);
  }
}

/// The OpenAI GPT-3 engine used in the API call.
///
/// For more information on the engines, refer to [the OpenAI documentation](https://beta.openai.com/docs/engines).
class Engine {
  static const ada = Engine._('ada');
  static const babbage = Engine._('babbage');
  static const curie = Engine._('curie');
  static const curieInstruct = Engine._('curie-instruct-beta');
  static const davinci = Engine._('davinci');
  static const davinciInstruct = Engine._('davinci-instruct-beta');
  final String _string;

  const Engine._(this._string);

  @override
  String toString() => _string;
}
